# Adaptive Learning Companion with RAG and Fine-Tuning

## Author: Randa Benammar  
## Date: 2025-01-20  
## Project: Adaptive Learning Companion with RAG and Fine-Tuning  

---

## Table of Contents
1. [Introduction](#introduction)
2. [Frameworks](#frameworks)
3. [Installation](#installation)
4. [Imports](#imports)
5. [Config](#config)
6. [Groq Client](#groq-client)
7. [Emotion Client](#emotion-client)
8. [PDF Processor](#pdf-processor)
9. [RAG Pipeline](#rag-pipeline)
10. [RAG Init](#rag-init)
11. [Dataset Builder](#dataset-builder)
12. [LoRA FineTuner](#lora-finetuner)
13. [Complete Pipeline](#complete-pipeline)
14. [Test RAG](#test-rag)
15. [Test Emotion](#test-emotion)
16. [Fine-Tuning Demo](#finetuning-demo)
17. [Comparison Demo](#comparison-demo)
18. [Interactive Session](#interactive-session)
19. [Conclusion](#conclusion)

---

## Introduction

### Architecture Diagram
```
[Insert ASCII art diagram here]
```

### Objectives
- Provide adaptive learning through conversational AI.
- Utilize retrieval-augmented generation (RAG) for enhanced responses.

### Components Explanation
- **ChromaDB**: An efficient database for storing embeddings.
- **SentenceTransformer**: For sentence embedding generation.
- **PEFT/LoRA**: Methods for fine-tuning models efficiently.
- **Groq API**: For accessing Groq models.
- **HuggingFace API**: For model management and usage.

---

## Frameworks
Detailed explanation of the following frameworks:
- **ChromaDB**: A database designed for embeddings with efficient querying capabilities.
- **SentenceTransformer**: A library for generating sentence embeddings.
- **PEFT/LoRA**: Techniques for parameter-efficient fine-tuning of transformer models.
- **Groq API**: Provides access to Groq's powerful models for inference.
- **HuggingFace API**: An ecosystem for managing and deploying AI models.

---

## Installation
```python
!pip install torch transformers chromadb sentence-transformers peft datasets pypdf pymupdf requests pandas --upgrade
```

---

## Imports
```python
import torch
from transformers import ... # Add necessary imports
from peft import ...
from chromadb import ...
from sentence_transformers import ...
from datasets import ...
from pathlib import Path
from typing import ...
```

---

## Config
```python
# API Key configuration
GROQ_API_KEY = 'your_groq_api_key'
HUGGINGFACE_API_KEY = 'your_huggingface_api_key'
MODEL_CONFIG = {
    'model_name': 'your_model_name',
    'parameters': {...}
}
```

---

## Groq Client
```python
class GroqClient:
    """
    A client to interact with the Groq API.
    """
    def __init__(self, api_key: str):
        self.api_key = api_key
        # Additional initialization code

    def generate(self, input_data: str):
        """
        Generate output from Groq model.
        """
        # Implementation code with error handling

    def test_connection(self):
        """
        Test the connection to the Groq API.
        """
        # Implementation code
```

---

## Emotion Client
```python
class EmotionClient:
    """
    A client to analyze emotions from text.
    """
    def __init__(self):
        self.emotion_mapping = {...}
        # Initialization code

    def analyze(self, text: str):
        """
        Analyze the text for emotions.
        """
        # Implementation code
```

---

## PDF Processor
```python
class PDFProcessor:
    """
    Processes PDF files to extract text.
    """
    def extract_text_from_pdf(self, pdf_path: str):
        """
        Extract text from the provided PDF file.
        """
        # Implementation code

    def clean_text(self, text: str):
        """
        Clean extracted text for processing.
        """
        # Implementation code

    def chunk_text(self, text: str, chunk_size: int = 500, overlap: int = 50):
        """
        Split text into chunks for processing.
        """
        # Implementation code
```

---

## RAG Pipeline
```python
class EnhancedRAGPipeline:
    """
    Implements an enhanced retrieval-augmented generation pipeline.
    """
    def __init__(self):
        # Initialization code

    def add_documents(self, documents: list):
        """
        Add documents to the RAG pipeline.
        """
        # Implementation code

    def add_pdfs(self, pdf_paths: list):
        """
        Add PDF documents to the RAG pipeline.
        """
        # Implementation code

    def retrieve(self, query: str):
        """
        Retrieve relevant documents for the given query.
        """
        # Implementation code

    def get_stats(self):
        """
        Get statistics on the RAG pipeline.
        """
        # Implementation code
```

---

## RAG Init
```python
# Initialize the components
sentence_transformer = SentenceTransformer('model_name')
chroma_client = ChromaDB(...)
rag_pipeline = EnhancedRAGPipeline()
rag_pipeline.add_documents(default_documents)
```

---

## Dataset Builder
```python
class FineTuningDatasetBuilder:
    """
    Builds datasets for fine-tuning.
    """
    def generate_training_pairs_from_rag(self, rag_pipeline):
        """
        Generate training pairs from RAG pipeline.
        """
        # Implementation code

    def prepare_for_training(self, data):
        """
        Prepare data for training.
        """
        # Implementation code
```

---

## LoRA FineTuner
```python
class LoRAFineTuner:
    """
    Fine-tunes a model using LoRA.
    """
    def load_base_model(self):
        """
        Load base model for fine-tuning.
        """
        # Implementation code

    def configure_lora(self, model):
        """
        Configure LoRA parameters for the model.
        """
        # Implementation code

    def train(self, training_data):
        """
        Train the model on the provided data.
        """
        # Implementation code

    def generate(self, input_data):
        """
        Generate output after fine-tuning.
        """
        # Implementation code
```

---

## Complete Pipeline
```python
class CompletePipeline:
    """
    Integrates all components into a single pipeline.
    """
    def run_finetuning(self):
        """
        Run the fine-tuning process.
        """
        # Implementation code

    def compare_models(self):
        """
        Compare the base and fine-tuned models.
        """
        # Implementation code

    def interactive_session(self):
        """
        Launch an interactive chat session.
        """
        # Implementation code
```

---

## Test RAG
```python
# Demo code to test RAG retrieval
query = "Sample query"
results = rag_pipeline.retrieve(query)
print(results)
```

---

## Test Emotion
```python
# Demo code to test emotion detection
text = "Sample text"
emotions = emotion_client.analyze(text)
print(emotions)
```

---

## Fine-Tuning Demo
```python
# Code to execute fine-tuning
fine_tuner = LoRAFineTuner()
fine_tuner.train(training_data)
```

---

## Comparison Demo
```python
# Code to compare Groq base model vs fine-tuned LoRA model
comparison_results = complete_pipeline.compare_models()
print(comparison_results)
```

---

## Interactive Session
```python
# Code to launch interactive chat session
complete_pipeline.interactive_session()
```

---

## Conclusion
### Summary
- Summary of the project outcomes.
- Results and performance metrics.
- Future improvements and next steps.

---

