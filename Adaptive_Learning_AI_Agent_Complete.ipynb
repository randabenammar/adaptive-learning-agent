{\n "cells": [\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "# ðŸŽ“ Adaptive Learning Companion - AI Agent with RAG & Fine-Tuning",\n    "**Author:** Randa Benammar | **Date:** 2025-01-20 | **Version:** 1.0"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## Table of Contents",\n    "1. Introduction",\n    "2. Architecture Overview",\n    "3. Dependencies Installation",\n    "4. API Configuration",\n    "5. GroqClient Class",\n    "6. EmotionClient Class",\n    "7. PDFProcessor Class",\n    "8. Enhanced RAG Pipeline",\n    "9. Fine-Tuning Dataset Builder",\n    "10. LoRA Fine Tuner",\n    "11. Complete Pipeline",\n    "12. RAG Retrieval Test",\n    "13. Emotion Detection Test",\n    "14. Fine-Tuning Execution",\n    "15. Model Comparison",\n    "16. Interactive Session",\n    "17. Conclusion"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## Architecture Explanation",\n    "This section explains the architecture of the Adaptive Learning AI Agent using ASCII diagrams.",\n    "```plaintext",\n    "RAG Pipeline: [User Input] --> [Emotion Detection] --> [LLM Generation]",\n    "```,\n    "... (other diagrams can be added here)"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## Frameworks Justification Table",\n    "| Framework | Justification |",\n    "|-----------|---------------|",\n    "| ChromaDB | ... |",\n    "| SentenceTransformer | ... |",\n    "| PEFT/LoRA | ... |",\n    "| Groq API | ... |",\n    "| HuggingFace API | ... |"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Installation of dependencies" ,\n    "!pip install torch==1.10.0 transformers==4.21.0 chromadb==0.3.0 sentence-transformers==2.1.0 peft==0.2.0 datasets==1.19.0 pypdf==1.0.0 pymupdf==1.19.0 requests==2.26.0 pandas==1.3.3"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# All imports with error handling" ,\n    "try:",\n    "    import torch",\n    "    import transformers",\n    "    import chromadb",\n    "    from sentence_transformers import SentenceTransformer",\n    "    from peft import LoRA, PEFTConfig",\n    "    import requests",\n    "    import pandas as pd",\n    "except ImportError as e:",\n    "    print(f'Error importing modules: {e}')"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# API configuration" ,\n    "import os",\n    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')",\n    "HUGGINGFACE_API_KEY = os.getenv('HUGGINGFACE_API_KEY')",\n    "MODEL_CONFIG = {'model_name': 'your_model_name', 'version': '1.0'}"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# GroqClient class" ,\n    "class GroqClient:",\n    "    def __init__(self, api_key):",\n    "        self.api_key = api_key",\n    "    def generate(self, prompt):",\n    "        # Implementation here...",\n    "    def test_connection(self):",\n    "        # Implementation here..."\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# EmotionClient class" ,\n    "class EmotionClient:",\n    "    def __init__(self):",\n    "        pass",\n    "    def analyze(self, text):",\n    "        # Implementation here..."\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# PDFProcessor class" ,\n    "class PDFProcessor:",\n    "    def extract_text_from_pdf(self, pdf_path):",\n    "        # Implementation here...",\n    "    def clean_text(self, text):",\n    "        # Implementation here...",\n    "    def chunk_text(self, text):",\n    "        # Implementation here..."\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# EnhancedRAGPipeline class" ,\n    "class EnhancedRAGPipeline:",\n    "    def __init__(self):",\n    "        # Initialization code here...",\n    "    def add_documents(self):",\n    "        # Implementation here...",\n    "    def add_pdfs(self):",\n    "        # Implementation here...",\n    "    def retrieve(self):",\n    "        # Implementation here...",\n    "    def get_stats(self):",\n    "        # Implementation here..."\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# RAG initialization" ,\n    "rag_pipeline = EnhancedRAGPipeline()",\n    "rag_pipeline.add_documents()"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## Upload PDFs Section",\n    "This section allows users to upload PDFs for processing."\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# FineTuningDatasetBuilder class" ,\n    "class FineTuningDatasetBuilder:",\n    "    def generate_training_pairs_from_rag(self):",\n    "        # Implementation here...",\n    "    def prepare_for_training(self):",\n    "        # Implementation here..."\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# LoRAFineTuner class" ,\n    "class LoRAFineTuner:",\n    "    def load_base_model(self):",\n    "        # Implementation here...",\n    "    def configure_lora(self):",\n    "        # Implementation here...",\n    "    def train(self):",\n    "        # Implementation here...",\n    "    def generate(self):",\n    "        # Implementation here..."\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# CompletePipeline class" ,\n    "class CompletePipeline:",\n    "    def run_finetuning(self):",\n    "        # Implementation here...",\n    "    def compare_models(self):",\n    "        # Implementation here...",\n    "    def interactive_session(self):",\n    "        # Implementation here..."\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# RAG retrieval test demo" ,\n    "example_query = 'What is adaptive learning?'"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Emotion detection test demo" ,\n    "example_text = 'I feel happy today!'"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Fine-tuning execution demo" ,\n    "# Uncomment the following line to execute fine-tuning:" ,\n    "# fine_tuner.train()"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Model comparison demo" ,\n    "# Uncomment the following line to compare models:" ,\n    "# comparison_results = compare_models()"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Interactive session launcher" ,\n    "# Uncomment the following line to start an interactive session:" ,\n    "# pipeline.interactive_session()"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## Conclusion",\n    "This section summarizes the results and outlines next steps."\n   ]\n  }\n ],\n "metadata": {\n  "kernelspec": {\n   "display_name": "Python 3",\n   "language": "python",\n   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.7.0"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 2\n}